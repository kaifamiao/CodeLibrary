web-crawler
给定一个链接<code>startUrl</code> 和一个接口<code>HtmlParser</code>，请你实现一个网络爬虫，以实现爬取同<code>startUrl</code>拥有相同<strong>域名标签</strong>的全部链接。该爬虫得到的全部链接可以<strong>任何顺序</strong>返回结果。

你的网络爬虫应当按照如下模式工作：

<ul>
	自链接<code>startUrl</code>开始爬取
	调用<code>HtmlParser.getUrls(url)</code>来获得链接<code>url</code>页面中的全部链接
	同一个链接最多只爬取一次
	只输出<strong>域名</strong>与<strong></strong><code>startUrl</code><strong>相同</strong>的链接集合
</ul>

<img alt="" src="https://assets.leetcode.com/uploads/2019/08/13/urlhostname.png" style="height: 164px; width: 600px;">

如上所示的一个链接，其域名为<code>example.org</code>。简单起见，你可以假设所有的链接都采用<strong>http协议</strong>并没有指定<strong>端口</strong>。例如，链接<code>http://leetcode.com/problems</code>和<code>http://leetcode.com/contest</code>是同一个域名下的，而链接<code>http://example.org/test</code>和<code>http://example.com/abc</code> 是不在同一域名下的。

<code>HtmlParser</code> 接口定义如下：

<pre>interface HtmlParser {
  // 返回给定 url 对应的页面中的全部 url 。
  public List&lt;String&gt; getUrls(String url);
}</pre>

下面是两个实例，用以解释该问题的设计功能，对于自定义测试，你可以使用三个变量<code>urls</code>,<code>edges</code>和<code>startUrl</code>。注意在代码实现中，你只可以访问<code>startUrl</code>，而<code>urls</code>和<code>edges</code>不可以在你的代码中被直接访问。



<strong>示例 1：</strong>

<img alt="" src="https://assets.leetcode.com/uploads/2019/10/23/sample_2_1497.png" style="height: 300px; width: 610px;">

<pre><strong>输入：
</strong>urls = [
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.google.com&quot;,
 &quot;http://news.yahoo.com/us&quot;
]
edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]
startUrl = &quot;http://news.yahoo.com/news/topics/&quot;
<strong>输出：</strong>[
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.yahoo.com/us&quot;
]
</pre>

<strong>示例 2：</strong>

<strong><img alt="" src="https://assets.leetcode.com/uploads/2019/10/23/sample_3_1497.png" style="height: 270px; width: 540px;"></strong>

<pre><strong>输入：</strong>
urls = [
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.google.com&quot;
]
edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]
startUrl = &quot;http://news.google.com&quot;
<strong>输入：</strong>[&quot;http://news.google.com&quot;]
<strong>解释：</strong>startUrl 链接到所有其他不共享相同主机名的页面。</pre>



<strong>提示：</strong>

<ul>
	<code>1 &lt;= urls.length &lt;= 1000</code>
	<code>1 &lt;= urls[i].length &lt;= 300</code>
	<code>startUrl</code>为<code>urls</code>中的一个。
	域名标签的长为1到63个字符（包括点），只能包含从&lsquo;a&rsquo;到&lsquo;z&rsquo;的ASCII字母、&lsquo;0&rsquo;到&lsquo;9&rsquo;的数字以及连字符即减号（&lsquo;-&rsquo;）。
	域名标签不会以连字符即减号（&lsquo;-&rsquo;）开头或结尾。
	关于域名有效性的约束可参考:<a href="https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames">https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames</a>
	你可以假定url库中不包含重复项。
</ul>

网络爬虫
Given a url <code>startUrl</code> and an interface <code>HtmlParser</code>, implement a webcrawler to crawl all links that are under the<strong>same hostname</strong> as<code>startUrl</code>.

Returnall urls obtained by your web crawler in <strong>any</strong> order.

Your crawler should:

<ul>
	Start from the page: <code>startUrl</code>
	Call <code>HtmlParser.getUrls(url)</code> to get all urls from a webpage of given url.
	Do not crawl the same link twice.
	Explore only the links that are under the <strong>same hostname</strong> as <code>startUrl</code>.
</ul>

<img alt="" src="https://assets.leetcode.com/uploads/2019/08/13/urlhostname.png" style="width: 600px; height: 164px;" />

As shown in the example url above, the hostname is <code>example.org</code>. For simplicity sake, you may assume allurls use <strong>http protocol</strong> without any<strong>port</strong> specified. For example, the urls<code>http://leetcode.com/problems</code> and<code>http://leetcode.com/contest</code> are under the same hostname, while urls <code>http://example.org/test</code> and <code>http://example.com/abc</code> are not under the same hostname.

The <code>HtmlParser</code> interface is defined as such:

<pre>
interface HtmlParser {
  // Return a list of all urls from a webpage of given <em>url</em>.
  public List&lt;String&gt; getUrls(String url);
}</pre>

Beloware two examples explaining the functionality of the problem, for custom testing purposes you&#39;ll have threevariables<code data-stringify-type="code">urls</code>,<code data-stringify-type="code">edges</code>and<code data-stringify-type="code">startUrl</code>. Notice that you will only have access to<code data-stringify-type="code">startUrl</code>in your code, while<code data-stringify-type="code">urls</code>and<code data-stringify-type="code">edges</code>are not directly accessible to you in code.


<strong>Example 1:</strong>

<img alt="" src="https://assets.leetcode.com/uploads/2019/10/23/sample_2_1497.png" style="width: 610px; height: 300px;" />

<pre>
<strong>Input:
</strong>urls = [
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.google.com&quot;,
 &quot;http://news.yahoo.com/us&quot;
]
edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]
startUrl = &quot;http://news.yahoo.com/news/topics/&quot;
<strong>Output:</strong> [
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.yahoo.com/us&quot;
]
</pre>

<strong>Example 2:</strong>

<strong><img alt="" src="https://assets.leetcode.com/uploads/2019/10/23/sample_3_1497.png" style="width: 540px; height: 270px;" /></strong>

<pre>
<strong>Input:</strong> 
urls = [
 &quot;http://news.yahoo.com&quot;,
 &quot;http://news.yahoo.com/news&quot;,
 &quot;http://news.yahoo.com/news/topics/&quot;,
 &quot;http://news.google.com&quot;
]
edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]
startUrl = &quot;http://news.google.com&quot;
<strong>Output:</strong> [&quot;http://news.google.com&quot;]
<strong>Explanation: </strong>The startUrl links to all other pages that do not share the same hostname.</pre>


<strong>Constraints:</strong>

<ul>
	<code>1 &lt;= urls.length &lt;= 1000</code>
	<code>1 &lt;= urls[i].length &lt;= 300</code>
	<code>startUrl</code>is one of the <code>urls</code>.
	Hostname label must be from 1 to 63 characters long, including the dots, may contain only the ASCII letters from &#39;a&#39; to&#39;z&#39;, digits from &#39;0&#39; to &#39;9&#39; and thehyphen-minuscharacter (&#39;-&#39;).
	The hostname may not start or end withthe hyphen-minus character (&#39;-&#39;).
	See:<a href="https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames">https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames</a>
	You may assume there&#39;reno duplicates in url library.
</ul>
